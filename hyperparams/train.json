{
    "$schema": "schema/pretrain_schema.json",
    "encoder_path": "params/original/encoder_bpe_40000.json",
    "bpe_path": "params/original/vocab_40000.bpe",
    "pretrained_lm_path": "/users/grads/r/rdalbest/Documents/FLaME/params/language_modeling__6_to_11_len_books_in_sentences_2019-03-08 18:45:14/transformer.pth",
    "freeze_lm": true,
    "seed": 333,
    "n_iter": 5,
    "epoch_size": 10000,
    "validation_frequency": 100,
    "test_split": 0.2,
    "validation_split": 0.2,
    "batch_size": 32,
    "n_embd": 768,
    "n_head": 12,
    "n_layer": 12,
    "n_pre_layer": 0,
    "n_post_layer": 2,
    "n_projection_layer": 1,
    "n_f_layer": 1,
    "embd_pdrop": 0.1,
    "attn_pdrop": 0.1,
    "resid_pdrop": 0.1,
    "lr": 5.0e-5,
    "b1": 0.9,
    "b2": 0.999,
    "eps": 1e-8,
    "lr_schedule": "warmup_linear",
    "lr_warmup": 0.002,
    "l2": 0.01,
    "vector_l2": true,
    "max_grad_norm": 1,
    "n_ctx": 512,
    "max_sequence_dim": 16,
    "lm_coefficient": 1.0,
    "distance_coefficient": 0.0,
    "distance_metric": "euclidean",
    "n_negative_sample": 5
}
